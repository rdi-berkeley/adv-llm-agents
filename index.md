---
layout: default
title: "CS294/194-280 <br> Advanced Large Language Model Agents"
permalink: /sp25
redirect_from:
 - /
---

### Prospective Students

- ***Students interested in the course should first try enrolling in the course in CalCentral. The class number for CS194-280 is 33840. The class number for CS294-280 is 33841. Please join the waitlist if the class is full.***
- ***We plan to expand the class size to allow more students to join. Please fill in the <a href="https://forms.gle/sfWW8M2w1LDTnQWm9">petition form</a> if you are on the waitlist or can't get added to the waitlist. You will receive an email notification around the beginning of the spring semester if you are allowed in.***
- ***<span style="color:red">For any questions, please email course staff at <a href="mailto:cs294280.sp25@gmail.com
">cs294280.sp25@gmail.com</a>.</span>***

## Course Staff

<table>
<tbody>
<tr>
<td>Instructor</td>
<td>(Guest) Co-instructor</td>
<td>(Guest) Co-instructor</td>
</tr>
<tr>
<td><img src="assets/dawn-berkeley.jpg" height=200/></td>
<td><img src="assets/XinyunChen.jpg" height=200/></td>
<td><img src="assets/KaiyuYang.jpg" height=200/></td>
</tr>
<tr>
<td><a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a></td>
<td>Xinyun Chen</td>
<td>Kaiyu Yang</td>
<tr>
<td>Professor, UC Berkeley</td>
<td>Research Scientist, <br> Google DeepMind</td>
<td>Research Scientist, <br> Meta FAIR</td>
</tr>
</tr>
</tbody>
</table>

Reader: Tara Pande

## Class Time and Location

Lecture: 4-6pm PT Monday at Anthro/Art Building 160

## Course Description

Large language model (LLM) agents have been an important frontier in AI, however, they still fall short critical skills, such as complex reasoning and planning, for solving hard problems and enabling end-to-end applications in real-world scenarios. Building on our [previous course](https://llmagents-learning.org/f24), this course dives deeper into advanced topics in LLM agents, focusing on reasoning, AI for mathematics, code generation, and program verification. We begin by introducing advanced inference and post-training techniques for building LLM agents that can search and plan. Then, we focus on two application domains: mathematics and programming. We study how LLMs can be used to prove mathematical theorems, as well as generate and reason about computer programs. Specifically, we will cover the following topics:
- Inference-time techniques for reasoning
- Post-training methods for reasoning
- Search and planning
- Agentic workflow, tool use, and functional calling
- LLMs for code generation and verification
- LLMs for mathematics: data curation, continual pretraining, and finetuning
- LLM agents for theorem proving and autoformalization

## Syllabus

Under development


## Enrollment and Grading

***Prerequisites:*** **Students are strongly encouraged to have had experience and basic understanding of Machine Learning and Deep Learning before taking this class, e.g., have taken courses such as CS182, CS188, and CS189.**

***Please fill out the <a href="https://forms.gle/sfWW8M2w1LDTnQWm9">petition form</a> if you are on the waitlist or can't get added to the waitlist.***

This is a variable-unit course.
All enrolled students are expected to participate in lectures in person and complete weekly reading summaries related to the course content.
Students enrolling in one unit are expected to submit an article that summarizes one of the lectures.
Students enrolling in more than one unit are expected to submit a lab assignment and a project instead of the article.
The project of students enrolling in 2 units should have a written report, which can be a survey in a certain area related to LLMs.
The project of students enrolling in 3 units should also have an implementation (coding) component that programmatically interacts with LLMs, and the project of students enrolling in 4 units should have a very significant implementation component with the potential for either real world impacts or intellectual contributions.
The grade breakdowns for students enrolled in different units are the following:

|                              | 1 unit | 2 units | 3/4 units |
|------------------------------|--------|---------|-----------|
| Participation                | 40%    | 16%     | 8%        |
| Reading Summaries & Q/A      | 10%    | 4%      | 2%        |
| Quizzes                      | 10%    | 4%      | 2%        |
| Article                      | 40%    |         |           |
| Lab                          |        | 16%     | 8%        |
| Project                      |        |         |           |
| &nbsp;&nbsp;*Proposal*       |        | 10%     | 10%       |
| &nbsp;&nbsp;*Milestone 1*    |        | 10%     | 10%       |
| &nbsp;&nbsp;*Milestone 2*    |        | 10%     | 10%       |
| &nbsp;&nbsp;*Presentation*   |        | 15%     | 15%       |
| &nbsp;&nbsp;*Report*         |        | 15%     | 15%       |
| &nbsp;&nbsp;*Implementation* |        |         | 20%       |

## Office Hours

TBA
